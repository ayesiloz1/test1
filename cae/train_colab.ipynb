{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62113548",
   "metadata": {},
   "source": [
    "# CAE Training on Google Colab\n",
    "**Weld Defect Detection - Convolutional Autoencoder**\n",
    "\n",
    "This notebook trains the CAE model using Colab's free GPU (10-20x faster than CPU)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f735c31",
   "metadata": {},
   "source": [
    "## 1. Setup - Enable GPU\n",
    "Go to **Runtime → Change runtime type → GPU (T4)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bc0815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b25e8e",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive & Upload Dataset\n",
    "Upload your `cae/dataset` folder to Google Drive first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4202f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set your dataset path (adjust if needed)\n",
    "DATASET_PATH = '/content/drive/MyDrive/RIAWELC/cae/dataset'\n",
    "OUTPUT_PATH = '/content/drive/MyDrive/RIAWELC/cae/models'\n",
    "\n",
    "import os\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "print(f\"Dataset path: {DATASET_PATH}\")\n",
    "print(f\"Output path: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700ea69a",
   "metadata": {},
   "source": [
    "## 3. Define Model & Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ImageNet normalization (same as CNN)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class DeconvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class CAE(nn.Module):\n",
    "    \"\"\"Convolutional Autoencoder for Anomaly Detection\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels=3, latent_dim=128):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock(in_channels, 32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.enc2 = ConvBlock(32, 64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.enc3 = ConvBlock(64, 128)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = ConvBlock(128, latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.dec3 = DeconvBlock(latent_dim, 128)\n",
    "        self.dec2 = DeconvBlock(128, 64)\n",
    "        self.dec1 = DeconvBlock(64, 32)\n",
    "        \n",
    "        # Output (no Sigmoid - using ImageNet normalized values)\n",
    "        self.output = nn.Conv2d(32, in_channels, kernel_size=3, padding=1)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = self.pool1(self.enc1(x))\n",
    "        x = self.pool2(self.enc2(x))\n",
    "        x = self.pool3(self.enc3(x))\n",
    "        x = self.bottleneck(x)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, z):\n",
    "        x = self.dec3(z)\n",
    "        x = self.dec2(x)\n",
    "        x = self.dec1(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        return self.decode(z)\n",
    "\n",
    "\n",
    "class NormalDataset(Dataset):\n",
    "    \"\"\"Dataset for training: normal images only\"\"\"\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        extensions = ['*.png', '*.jpg', '*.jpeg', '*.bmp', '*.tif', '*.tiff']\n",
    "        self.image_paths = []\n",
    "        for ext in extensions:\n",
    "            self.image_paths.extend(self.root_dir.glob(ext))\n",
    "        self.image_paths = sorted(self.image_paths)\n",
    "        print(f\"NormalDataset: Found {len(self.image_paths)} images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, str(self.image_paths[idx])\n",
    "\n",
    "\n",
    "class AnomalyDataset(Dataset):\n",
    "    \"\"\"Dataset for validation/testing: normal + defects with labels\"\"\"\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.defect_types = []\n",
    "        \n",
    "        extensions = ['*.png', '*.jpg', '*.jpeg', '*.bmp', '*.tif', '*.tiff']\n",
    "        \n",
    "        # Normal images (label=0)\n",
    "        normal_dir = self.root_dir / 'normal'\n",
    "        if normal_dir.exists():\n",
    "            for ext in extensions:\n",
    "                for p in normal_dir.glob(ext):\n",
    "                    self.image_paths.append(p)\n",
    "                    self.labels.append(0)\n",
    "                    self.defect_types.append('ND')\n",
    "        \n",
    "        # Defect images (label=1)\n",
    "        defect_dir = self.root_dir / 'defect'\n",
    "        if defect_dir.exists():\n",
    "            for defect_type in ['CR', 'LP', 'PO']:\n",
    "                type_dir = defect_dir / defect_type\n",
    "                if type_dir.exists():\n",
    "                    for ext in extensions:\n",
    "                        for p in type_dir.glob(ext):\n",
    "                            self.image_paths.append(p)\n",
    "                            self.labels.append(1)\n",
    "                            self.defect_types.append(defect_type)\n",
    "        \n",
    "        n_normal = sum(1 for l in self.labels if l == 0)\n",
    "        n_defect = sum(1 for l in self.labels if l == 1)\n",
    "        print(f\"AnomalyDataset: {len(self.image_paths)} images ({n_normal} normal, {n_defect} defects)\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.labels[idx], self.defect_types[idx], str(self.image_paths[idx])\n",
    "\n",
    "\n",
    "def get_transforms(image_size=224, augment=False):\n",
    "    if augment:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "        ])\n",
    "\n",
    "print(\"Model and Dataset classes defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9ee8fd",
   "metadata": {},
   "source": [
    "## 4. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters (optimized for Colab GPU)\n",
    "CONFIG = {\n",
    "    'image_size': 224,      # Full resolution\n",
    "    'batch_size': 64,       # Larger batch for GPU\n",
    "    'epochs': 50,\n",
    "    'learning_rate': 1e-3,\n",
    "    'weight_decay': 1e-5,\n",
    "    'latent_dim': 128,\n",
    "    'num_workers': 2,       # Colab works well with 2\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9b1268",
   "metadata": {},
   "source": [
    "## 5. Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d554c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_transform = get_transforms(CONFIG['image_size'], augment=True)\n",
    "val_transform = get_transforms(CONFIG['image_size'], augment=False)\n",
    "\n",
    "train_dataset = NormalDataset(f\"{DATASET_PATH}/training/normal\", train_transform)\n",
    "val_dataset = AnomalyDataset(f\"{DATASET_PATH}/validation\", val_transform)\n",
    "test_dataset = AnomalyDataset(f\"{DATASET_PATH}/testing\", val_transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], \n",
    "                          shuffle=True, num_workers=CONFIG['num_workers'], pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], \n",
    "                        shuffle=False, num_workers=CONFIG['num_workers'], pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], \n",
    "                         shuffle=False, num_workers=CONFIG['num_workers'], pin_memory=True)\n",
    "\n",
    "print(f\"\\nTrain: {len(train_loader)} batches\")\n",
    "print(f\"Val: {len(val_loader)} batches\")\n",
    "print(f\"Test: {len(test_loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ac4e14",
   "metadata": {},
   "source": [
    "## 6. Initialize Model & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaf9117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create model\n",
    "model = CAE(latent_dim=CONFIG['latent_dim']).to(device)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Loss, optimizer, scheduler\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
    "\n",
    "# Training history\n",
    "history = {'train_loss': [], 'val_auc': [], 'threshold': []}\n",
    "best_auc = 0\n",
    "best_threshold = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e932a208",
   "metadata": {},
   "source": [
    "## 7. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e0aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, device):\n",
    "    \"\"\"Validate and compute AUC\"\"\"\n",
    "    model.eval()\n",
    "    all_errors, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels, _, _ in val_loader:\n",
    "            images = images.to(device)\n",
    "            recon = model(images)\n",
    "            errors = torch.mean((images - recon) ** 2, dim=[1, 2, 3])\n",
    "            all_errors.extend(errors.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    all_errors = np.array(all_errors)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Compute AUC\n",
    "    auc = roc_auc_score(all_labels, all_errors)\n",
    "    \n",
    "    # Find optimal threshold\n",
    "    thresholds = np.percentile(all_errors[all_labels == 0], [90, 95, 99])\n",
    "    best_f1, best_thresh = 0, thresholds[1]\n",
    "    for t in np.linspace(all_errors.min(), all_errors.max(), 100):\n",
    "        preds = (all_errors > t).astype(int)\n",
    "        f1 = f1_score(all_labels, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_thresh = f1, t\n",
    "    \n",
    "    return auc, best_thresh, best_f1\n",
    "\n",
    "\n",
    "# Training loop\n",
    "print(\"Starting training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{CONFIG['epochs']}\")\n",
    "    for images, _ in pbar:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        recon = model(images)\n",
    "        loss = criterion(recon, images)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.6f}'})\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    # Validate\n",
    "    val_auc, threshold, val_f1 = validate(model, val_loader, device)\n",
    "    scheduler.step(val_auc)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_auc'].append(val_auc)\n",
    "    history['threshold'].append(threshold)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Loss={train_loss:.6f}, AUC={val_auc:.4f}, F1={val_f1:.4f}, Thresh={threshold:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        best_threshold = threshold\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'threshold': threshold,\n",
    "            'auc': val_auc,\n",
    "            'config': CONFIG,\n",
    "            'epoch': epoch\n",
    "        }, f\"{OUTPUT_PATH}/best_cae_model.pth\")\n",
    "        print(f\"  ★ New best model saved! AUC: {val_auc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Training complete! Best AUC: {best_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f029a82",
   "metadata": {},
   "source": [
    "## 8. Test Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9ad642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(f\"{OUTPUT_PATH}/best_cae_model.pth\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "threshold = checkpoint['threshold']\n",
    "\n",
    "# Test\n",
    "model.eval()\n",
    "all_errors, all_labels, all_types = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, defect_types, _ in tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        recon = model(images)\n",
    "        errors = torch.mean((images - recon) ** 2, dim=[1, 2, 3])\n",
    "        all_errors.extend(errors.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_types.extend(defect_types)\n",
    "\n",
    "all_errors = np.array(all_errors)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Compute metrics\n",
    "test_auc = roc_auc_score(all_labels, all_errors)\n",
    "predictions = (all_errors > threshold).astype(int)\n",
    "test_f1 = f1_score(all_labels, predictions)\n",
    "accuracy = np.mean(predictions == all_labels)\n",
    "\n",
    "print(f\"\\n{'='*40}\")\n",
    "print(f\"TEST RESULTS\")\n",
    "print(f\"{'='*40}\")\n",
    "print(f\"AUC Score: {test_auc:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Threshold: {threshold:.6f}\")\n",
    "\n",
    "# Per-class analysis\n",
    "print(f\"\\nPer-class Detection Rate:\")\n",
    "for dtype in ['ND', 'CR', 'LP', 'PO']:\n",
    "    mask = np.array(all_types) == dtype\n",
    "    if mask.sum() > 0:\n",
    "        if dtype == 'ND':\n",
    "            rate = np.mean(predictions[mask] == 0)  # Normal should be predicted as 0\n",
    "            print(f\"  {dtype} (Normal): {rate:.2%} correct\")\n",
    "        else:\n",
    "            rate = np.mean(predictions[mask] == 1)  # Defects should be predicted as 1\n",
    "            print(f\"  {dtype} (Defect): {rate:.2%} detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2555dcda",
   "metadata": {},
   "source": [
    "## 9. Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88fc02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model with all info\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'threshold': threshold,\n",
    "    'test_auc': test_auc,\n",
    "    'test_f1': test_f1,\n",
    "    'config': CONFIG,\n",
    "}, f\"{OUTPUT_PATH}/cae_final.pth\")\n",
    "\n",
    "print(f\"Model saved to: {OUTPUT_PATH}/cae_final.pth\")\n",
    "print(\"\\nDownload from Google Drive or use:\")\n",
    "\n",
    "# Download directly\n",
    "from google.colab import files\n",
    "files.download(f\"{OUTPUT_PATH}/cae_final.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a914a3",
   "metadata": {},
   "source": [
    "## 10. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b837d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(history['train_loss'])\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('MSE Loss')\n",
    "\n",
    "axes[1].plot(history['val_auc'])\n",
    "axes[1].set_title('Validation AUC')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('AUC Score')\n",
    "axes[1].axhline(y=best_auc, color='r', linestyle='--', label=f'Best: {best_auc:.4f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_PATH}/training_history.png\", dpi=150)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
